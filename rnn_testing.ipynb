{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib \n",
    "import joblib\n",
    "from rdkit.Chem.Draw import IPythonConsole #Needed to show molecules+\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "from syba.syba import SybaClassifier, SmiMolSupplier\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(None, 1024,)))\n",
    "model.add(layers.Dense(64, activation='relu'))#, input_shape=(1024,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_my_model():\n",
    "    model = keras.Sequential()\n",
    "    # Add an Embedding layer expecting input vocab of size 1000, and\n",
    "    # output embedding dimension of size 64.\n",
    "    model.add(layers.Embedding(input_dim=1024, output_dim=1))\n",
    "\n",
    "    # Add a LSTM layer with 128 internal units.\n",
    "    model.add(layers.LSTM(128))\n",
    "\n",
    "    # Add a Dense layer with 10 units.\n",
    "    model.add(layers.Dense(64))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_my_model_v6():\n",
    "    model = keras.Sequential()\n",
    "    # Add an Embedding layer expecting input vocab of size 1000, and\n",
    "    # output embedding dimension of size 64.\n",
    "    model.add(layers.Embedding(input_dim=1024, output_dim=1))\n",
    "\n",
    "    # Add a LSTM layer with 128 internal units.\n",
    "    model.add(layers.LSTM(128))\n",
    "    # Add a Dense layer with 10 units.\n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.Dense(32))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['mae', 'accuracy'])\n",
    "    #model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 1)           1024      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 75,905\n",
      "Trainable params: 75,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_load = create_my_model()\n",
    "rnn_load.load_weights('./rnn_weights_12_22.h5')\n",
    "rnn_load.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='../data/romain/pub1.csv' mode='rt' encoding='UTF-8'>\n",
      "[[0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.99999386]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]]\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "nBits = 1024\n",
    "\n",
    "inpath = \"../data/romain/\"\n",
    "outpath = \"../out/RNN/V6/\"\n",
    "i = 0\n",
    "files = [\"pub1.csv\"]\n",
    "for f in files:\n",
    "    with open(outpath+f, \"w\") as out:\n",
    "        out.write(\"idx,smiles,atoms,LSTM\\n\")\n",
    "        print(open(inpath+f, mode=\"rt\"))\n",
    "        test = np.array([np.array(Chem.GetMorganFingerprintAsBitVect(spls[0],2,nBits=nBits)) for spls in SmiMolSupplier(open(inpath+f, mode=\"rt\"), header=True, smi_col=0)])\n",
    "        pri\n",
    "        pr = rnn_load.predict(test)\n",
    "        print(pr)\n",
    "        print(len(pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c47626719d52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrnn_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_my_model_v6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrnn_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./rnn_lstm_V6.1000.10_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrnn_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rdkit-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2202\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rdkit-env/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rdkit-env/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "rnn_load = create_my_model_v6()\n",
    "rnn_load.load_weights('./rnn_lstm_V6.1000.10_weights.h5')\n",
    "rnn_load.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: model/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-387b2b8de4b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrnn_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rdkit-env/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rdkit-env/lib/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: model/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "rnn_load = keras.models.load_model('model')\n",
    "rnn_load.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load syba\n",
    "syba = SybaClassifier()\n",
    "syba.fitDefaultScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999937 ]\n",
      " [0.9999937 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.99999386]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]\n",
      " [0.9999938 ]]\n",
      "40\n",
      "[[0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999937]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999937]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999937]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]\n",
      " [0.9999938]]\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n#          INP_FILENAME,      SMI_COL,  OUT_FILENAME\\nfiles = [(\"structures_1.csv.gz\", 2, \"train_set_hs.csv\"), (\"structures_2.csv.gz\", 1, \"train_set_es.csv\")]\\nfor f, col, out_filename in files:\\n    with open(outpath+f, \"w\") as out:\\n        out.write(\"idx,smiles,atoms,LSTM\\n\")\\n        finger_prints = [Chem.GetMorganFingerprintAsBitVect(spls[0],2,nBits=nBits) for spls in SmiMolSupplier(open(inpath+f, mode=\"rt\"), header=True, smi_col=1)]\\n        for fps in finger_prints:\\n            fps = np.array(fps)\\n            print(\"wesh: \", i)\\n            i += 1\\n            out.write(\"{},{},{},{}\\n\".format(idx, smi, atoms, rnn_load.predict(fps)))\\n        print(\"Fichier \" + f + \" traité\")\\n\\nprint(\"Phase 2 fini\")\\n\\n\\nfiles = [\"smiles_fig7.csv\"]\\nfor f in files:\\n    with open(outpath+f, \"w\") as out:\\n        out.write(\"idx,smiles,atoms,LSTM\\n\")\\n        finger_prints = [Chem.GetMorganFingerprintAsBitVect(spls[0],2,nBits=nBits) for spls in SmiMolSupplier(open(inpath+f, mode=\"rt\"), header=True, smi_col=1)]\\n        for fps in finger_prints:\\n            fps = np.array(fps)\\n            print(\"wesh: \", i)\\n            i += 1\\n            out.write(\"{},{},{},{}\\n\".format(idx, smi, atoms, rnn_load.predict(fps)))\\n        print(\"Fichier \" + f + \" traité\")\\n        \\nprint(\"Phase 3 fini\")\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nBits = 1024\n",
    "\n",
    "inpath = \"../data/\"\n",
    "outpath = \"../out/RNN/V6/\"\n",
    "i = 0\n",
    "files = [\"test_set_mc_es.csv\", \"test_set_mc_hs.csv\", \"test_set_cp_es.csv\", \"test_set_cp_hs.csv\"]\n",
    "for f in files:\n",
    "    with open(outpath+f, \"w\") as out:\n",
    "        out.write(\"idx,smiles,atoms,LSTM\\n\")\n",
    "        test = np.array([np.array(Chem.GetMorganFingerprintAsBitVect(spls[0],2,nBits=nBits)) for spls in SmiMolSupplier(open(inpath+f, mode=\"rt\"), header=True, smi_col=1)])\n",
    "        \n",
    "        pr = rnn_load.predict(test)\n",
    "        print(pr)\n",
    "        print(len(pr))\n",
    "        \"\"\"\n",
    "        \n",
    "        for fps in finger_prints:\n",
    "            print(\"wesh: \", i)\n",
    "            i += 1\n",
    "            fps = np.array(fps)\n",
    "            \n",
    "            fps = fps.reshape((1024))\n",
    "            fps = fps.astype('float32')\n",
    "            print(np.shape(fps))\n",
    "            print(rnn_load.predict(fps))\n",
    "            print(len(rnn_load.predict(fps)))\n",
    "            print(model.predict([fps]))\n",
    "            print(len(model.predict([fps])))\n",
    "            break;\n",
    "            #out.write(\"{},{},{},{}\\n\".format(idx, smi, atoms, rnn_load.predict(fps)))\n",
    "        print(\"Fichier \" + f + \" traité\")\n",
    "print(\"Phase 1 fini\")\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "#          INP_FILENAME,      SMI_COL,  OUT_FILENAME\n",
    "files = [(\"structures_1.csv.gz\", 2, \"train_set_hs.csv\"), (\"structures_2.csv.gz\", 1, \"train_set_es.csv\")]\n",
    "for f, col, out_filename in files:\n",
    "    with open(outpath+f, \"w\") as out:\n",
    "        out.write(\"idx,smiles,atoms,LSTM\\n\")\n",
    "        finger_prints = [Chem.GetMorganFingerprintAsBitVect(spls[0],2,nBits=nBits) for spls in SmiMolSupplier(open(inpath+f, mode=\"rt\"), header=True, smi_col=1)]\n",
    "        for fps in finger_prints:\n",
    "            fps = np.array(fps)\n",
    "            print(\"wesh: \", i)\n",
    "            i += 1\n",
    "            out.write(\"{},{},{},{}\\n\".format(idx, smi, atoms, rnn_load.predict(fps)))\n",
    "        print(\"Fichier \" + f + \" traité\")\n",
    "\n",
    "print(\"Phase 2 fini\")\n",
    "\n",
    "\n",
    "files = [\"smiles_fig7.csv\"]\n",
    "for f in files:\n",
    "    with open(outpath+f, \"w\") as out:\n",
    "        out.write(\"idx,smiles,atoms,LSTM\\n\")\n",
    "        finger_prints = [Chem.GetMorganFingerprintAsBitVect(spls[0],2,nBits=nBits) for spls in SmiMolSupplier(open(inpath+f, mode=\"rt\"), header=True, smi_col=1)]\n",
    "        for fps in finger_prints:\n",
    "            fps = np.array(fps)\n",
    "            print(\"wesh: \", i)\n",
    "            i += 1\n",
    "            out.write(\"{},{},{},{}\\n\".format(idx, smi, atoms, rnn_load.predict(fps)))\n",
    "        print(\"Fichier \" + f + \" traité\")\n",
    "        \n",
    "print(\"Phase 3 fini\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBits = 1024\n",
    "\n",
    "inpath = \"../data/marjo\"\n",
    "outpath = \"../out/RNN/Marjo\"\n",
    "\n",
    "files = [\"savith.csv\", \"scubidooth.csv\", \"gdb_complexth.csv\", \"nonpherth.csv\", \"zinc_randomth.csv\"]\n",
    "\n",
    "for f in files:\n",
    "    with open(inpath+f) as inp, open(outpath+f, \"w\") as out:\n",
    "        header = inp.readline().strip()\n",
    "        #out.write(header)\n",
    "        out.write(\"smiles,syba,LstmScore\\n\")\n",
    "        \n",
    "        data = np.array([np.array(Chem.GetMorganFingerprintAsBitVect(spls[0],2,nBits=nBits)) for spls in SmiMolSupplier(open(inpath+f, mode=\"rt\"), header=True, smi_col=0)])    \n",
    "        pr = rnn_load.predict(data)\n",
    "        i = 0\n",
    "        for line in inp:\n",
    "            smi = line.strip().split(\",\")[0]\n",
    "            #fingerprint = np.array(Chem.GetMorganFingerprintAsBitVect(smi,2,nBits=nBits)) \n",
    "            out.write(\"{},{},{}\\n\".format(smi, syba.predict(smi), pr[0][i][0]))\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBits = 1024\n",
    "i = 0\n",
    "inpath = \"../data/\"\n",
    "outpath = \"../out/RNN/LSTM_V1\"\n",
    "files = [\"test_set_mc_es.csv\", \"test_set_mc_hs.csv\", \"test_set_cp_es.csv\", \"test_set_cp_hs.csv\"]\n",
    "for f in files:\n",
    "    with open(inpath+f) as inp, open(outpath+f, \"w\") as out:\n",
    "        header = inp.readline().strip()\n",
    "        out.write(header)\n",
    "        out.write(\"idx,smiles,atoms,SybaScore,LstmScore\\n\")\n",
    "        data = np.array([np.array(Chem.GetMorganFingerprintAsBitVect(spls[0],2,nBits=nBits)) for spls in SmiMolSupplier(open(inpath+f, mode=\"rt\"), header=True, smi_col=1)])    \n",
    "        pr = rnn_load.predict(data)\n",
    "        i = 0\n",
    "        for line in inp:\n",
    "            idx, smi, atoms = line.strip().split(\",\")\n",
    "            out.write(\"{},{},{},{}\\n\".format(idx, smi, atoms, syba.predict(smi), pr[i]))\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-env",
   "language": "python",
   "name": "rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
